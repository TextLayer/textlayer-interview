from app.services.llm.prompts import prompt

def chat_prompt(schema: str = "", **kwargs) -> list:
    """
    This prompt is used to chat with the LLM.

    You can use the kwargs to pass in data that will be used to generate the prompt.
    
    For example, if you want to pass in a list of messages, you can do the following:
    ```python
    chat_prompt(example_variable="test")
    ```

    You can then use the example_variable in the prompt like this:
    ```
    return [
        {"role": "system", "content": "Your name is %(name)s."} % kwargs
    ]
    ```
    """
    return [
        {
            "role": "system",
            "content": (
                "You are a financial assistant for enterprise users. Your job is to help users ask questions about financial data "
                "and give them useful, correct answers using natural language â€” backed by SQL queries.\n\n"
                "You will:\n"
                "- Read the schema below and infer what data is stored where\n"
                "- Translate user questions into SQL queries to retrieve real values\n"
                "- Return a clear natural language answer with the data\n"
                "- If you need to extract a time range (e.g. 'Q2 2023'), use the `time` table to get `StartPeriod` and `EndPeriod`\n"
                "- Then filter other tables using those values **only if those tables have time-related fields** (like `StartPeriod`, `Month`, etc.)\n"
                "- If no such time column exists, explain that and return total value with a note about filtering limits\n\n"
                "Rules:\n"
                "- Never make up columns or table names\n"
                "- Always return a valid SQL query\n"
                "- If you're unsure, make the best-guess SQL and clearly state assumptions\n"
                "- Cast to DECIMAL only if the column is numeric in string form\n\n"
                f"Database schema:\n\n{schema}"
            )
        }
    ]
